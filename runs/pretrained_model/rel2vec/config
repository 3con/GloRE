batch_size=128
data_dir=data
decoder_embedding_file=None
decoder_size=3
decoder_vocab_size=55
do_validation=True
early_stop_tolerance=100000
embedding_size=300
encoder_embedding_file=left.20000.word2vec.vocab.npy
encoder_size=227
encoder_vocab_size=20000
fill_missing_scores=True
fresh_start=True
input_keep_prob=1.0
kb_relation_file=None
learning_rate=0.5
learning_rate_decay_factor=0.95
max_gradient_norm=5.0
maximum_steps=100000
mode=train
model_dir=runs/pretrained_model/rel2vec
num_layers=1
optimization_algorithm=adam
output_keep_prob=1.0
scores_output_file=None
size=300
steps_per_checkpoint=300
steps_per_summary=300
summarize_trainable_variables=False
test_data_dir=None
test_log=None
test_rank_input_file=None
test_rank_output_file=None
text_relation_file=None
train_embedding=True
train_log=None
use_attention=False
use_lstm=False
use_word2vec=True
vocab_file=vocab.txt
word2vec_normalization=None
